{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb552f9ef2f2200",
   "metadata": {},
   "source": [
    "# Runner Reidentification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaecf1c1460c01e1",
   "metadata": {},
   "source": [
    "in this notebook we start combining the track ids from different videos by computing similarity between the feature of each, runner (distinguished by trackid), after that we(I)(python)(M2 chip) use hungarian algorithm to assign a runner to another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d3c754008744d3",
   "metadata": {},
   "source": [
    "So the steps are:\n",
    "\n",
    "- select frontal cameras\n",
    "- aggregate feature by trackid\n",
    "- compute similarity matrix\n",
    "- assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0173d56efa5ef6",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "we firs import all the dependencies needed:\n",
    "\n",
    "- pandas - to manipulate dataframe\n",
    "- numpy - for matrix operations\n",
    "- select_bib_number - custom function that select ( given feature of all relevation for one track id ) the best bib number of the runner\n",
    "- aggregate_features - aggregate ( given feature of all relevation for one track id ) all the feature of a runner\n",
    "- temporal_overlap - checks if\n",
    "- compute_similarity\n",
    "- build_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:15:45.578505Z",
     "start_time": "2026-01-08T09:15:45.283336Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import aggregate_features, build_similarity_matrix"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:15:45.584904Z",
     "start_time": "2026-01-08T09:15:45.583097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#useful variables\n",
    "\n",
    "dataset_path = 'set_videos_2/info_runners_DATASET.csv'\n",
    "RightVideo_LeftVideo_features_output_path = 'set_videos_2/results_static_similarity_metric/RightVideo_LeftVideo_only_features.csv'\n",
    "RightVideo_agg_output_path = 'set_videos_2/results_static_similarity_metric/RightVideo_thresholded_detections_aggregated_features.csv'\n",
    "LeftVideo_agg_output_path = 'set_videos_2/results_static_similarity_metric/LeftVideo_thresholded_detections_aggregated_features.csv'"
   ],
   "id": "e55aad2fe9770927",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "4936d3ad7ab1d8d3",
   "metadata": {},
   "source": [
    "## STEP 1 - Select frontal cameras"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0b816a5dbea1b28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:15:46.878077Z",
     "start_time": "2026-01-08T09:15:46.842484Z"
    }
   },
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "#to reduce the error on track ids we select only the runners near to the camera with box_height threshold\n",
    "thresolded_runners = df[df['y2r'] - df['y1r'] > 550]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "aea671cefaf845e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:16:12.101595Z",
     "start_time": "2026-01-08T09:16:12.092319Z"
    }
   },
   "source": [
    "#select the two frontal camera\n",
    "df_RightVideo = thresolded_runners[thresolded_runners['cam'] == 'FD']\n",
    "df_LeftVideo = thresolded_runners[thresolded_runners['cam'] == 'FI']"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b9d94cf0d90713c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:16:13.807823Z",
     "start_time": "2026-01-08T09:16:13.799751Z"
    }
   },
   "source": [
    "print(f\"Right frontal camera runner detected: {len(df_RightVideo['trackid'].value_counts())}/? real runner\")\n",
    "print(f\"Left frontal camera runner detected: {len(df_LeftVideo['trackid'].value_counts())}/? real runner\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right frontal camera runner detected: 6/? real runner\n",
      "Left frontal camera runner detected: 6/? real runner\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "c04f107e10c9e74",
   "metadata": {},
   "source": [
    "## Step 2 - Aggregate feature by trackid"
   ]
  },
  {
   "cell_type": "code",
   "id": "454b5ade71871458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:16:15.237090Z",
     "start_time": "2026-01-08T09:16:15.200926Z"
    }
   },
   "source": [
    "track_ids_RightVideo = df_RightVideo.groupby(\"trackid\")  # group by track id\n",
    "track_ids_LeftVideo = df_LeftVideo.groupby(\"trackid\")  # group by track id\n",
    "\n",
    "#Right camera aggregation\n",
    "tracks_list_RightVideo = []\n",
    "for track_id, group in track_ids_RightVideo:\n",
    "    feature_vector = aggregate_features(group)\n",
    "    tracks_list_RightVideo.append(feature_vector)\n",
    "\n",
    "#Left camera aggregation\n",
    "tracks_list_LeftVideo = []\n",
    "for track_id, group in track_ids_LeftVideo:\n",
    "    feature_vector = aggregate_features(group)\n",
    "    tracks_list_LeftVideo.append(feature_vector)\n",
    "\n",
    "#now we have two list containing for each runner(trackid) his aggregated features"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "7586dcc8ef78dd9a",
   "metadata": {},
   "source": [
    "## Step 3 - Compute similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "92e97e6bbe16a70d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:16:16.281020Z",
     "start_time": "2026-01-08T09:16:16.275540Z"
    }
   },
   "source": "sim_matrix = build_similarity_matrix(tracks_list_RightVideo, tracks_list_LeftVideo, dynamic_metric=True)",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "2b963b9034a39f08",
   "metadata": {},
   "source": [
    "## Step 4 - Assignment"
   ]
  },
  {
   "cell_type": "code",
   "id": "6053010ba8688a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:16:17.690027Z",
     "start_time": "2026-01-08T09:16:17.351502Z"
    }
   },
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "runner_RightVideo, runner_LeftVideo = linear_sum_assignment(sim_matrix) # Hungarian algorithm implementazion\n",
    "for track in tracks_list_RightVideo:\n",
    "    track['match_id'] = None\n",
    "\n",
    "for track in tracks_list_LeftVideo:\n",
    "    track['match_id'] = None\n",
    "\n",
    "match_id = 0\n",
    "for c, cons in zip(runner_RightVideo, runner_LeftVideo):\n",
    "    match_id +=1\n",
    "    tracks_list_RightVideo[c]['match_id'] = match_id\n",
    "    tracks_list_LeftVideo[cons]['match_id'] = match_id"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "44a242e252f249f",
   "metadata": {},
   "source": [
    "## Aggregate features by match id\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6cc06d5d65a5052d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:16:19.428360Z",
     "start_time": "2026-01-08T09:16:19.403883Z"
    }
   },
   "source": [
    "# convert list series into Pandas Dataframe\n",
    "df_tracks_RightVideo = pd.DataFrame(tracks_list_RightVideo)\n",
    "df_tracks_LeftVideo = pd.DataFrame(tracks_list_LeftVideo)\n",
    "\n",
    "#concat\n",
    "df_all = pd.concat([df_tracks_RightVideo, df_tracks_LeftVideo], ignore_index=True, sort=False)\n",
    "grouped = df_all.groupby(\"match_id\")  # group by match id\n",
    "\n",
    "#Right camera aggregation\n",
    "match_id_list = []\n",
    "for match_id, group in grouped:\n",
    "    feature_vector = aggregate_features(group, with_frame=False)\n",
    "    match_id_list.append(feature_vector)\n",
    "#now we have two list containing for each runner(trackid) his aggregated features"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "c22e048c34646e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T09:16:20.437164Z",
     "start_time": "2026-01-08T09:16:20.426716Z"
    }
   },
   "source": [
    "runners_RightVideo_LeftVideo_features = pd.DataFrame(match_id_list)\n",
    "runners_RightVideo_LeftVideo_features.to_csv(RightVideo_LeftVideo_features_output_path, index=False)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "5700b290c3de516c",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "Add match id to relevation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "id": "4fdc2df161b450b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:15:46.893162Z",
     "start_time": "2025-12-04T16:15:46.889295Z"
    }
   },
   "source": [
    "df_RightVideo = df_RightVideo.merge(df_tracks_RightVideo[['trackid', 'match_id']], on='trackid', how='left')\n",
    "df_LeftVideo = df_LeftVideo.merge(df_tracks_LeftVideo[['trackid', 'match_id']], on='trackid', how='left')\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "6ca0213fb49dee77",
   "metadata": {},
   "source": [
    "Once we have the match_id we can edit the multiple features per runner with the aggregate one, by joining the two dataframes"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T16:15:46.903987Z",
     "start_time": "2025-12-04T16:15:46.895666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#keep only the non trait features\n",
    "df_RightVideo_no_trait = df_RightVideo[[\"match_id\", \"cam\",\"filename\",\"nframe\",\"trackid\",\"x1r\",\"y1r\",\"x2r\",\"y2r\",\"x1b\",\"y1b\",\"x2b\",\"y2b\"]]\n",
    "#aggregate with the aggregate features dataframe, on match_id\n",
    "df_RightVideo_agg = df_RightVideo_no_trait.merge(runners_RightVideo_LeftVideo_features, on='match_id', how='left')\n",
    "\n",
    "#keep only the non trait features\n",
    "df_LeftVideo_no_trait = df_LeftVideo[[\"match_id\", \"cam\",\"filename\",\"nframe\",\"trackid\",\"x1r\",\"y1r\",\"x2r\",\"y2r\",\"x1b\",\"y1b\",\"x2b\",\"y2b\"]]\n",
    "#aggregate with the aggregate features dataframe, on match_id\n",
    "df_LeftVideo_agg = df_LeftVideo_no_trait.merge(runners_RightVideo_LeftVideo_features, on='match_id', how='left')\n",
    "\n",
    "df_RightVideo_agg.to_csv(RightVideo_agg_output_path, index=False)\n",
    "df_LeftVideo_agg.to_csv(LeftVideo_agg_output_path, index=False)\n"
   ],
   "id": "e6c4f3ec38422b8d",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
