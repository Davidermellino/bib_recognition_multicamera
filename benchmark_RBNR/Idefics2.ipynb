{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "H100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec51ffd8ba934854946d5c05f062f3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8527ed7e6594c8fa7e6da80133d81a8",
              "IPY_MODEL_e2b24e273d554fa0985061860d3a665a",
              "IPY_MODEL_0626152a942a4c8998b84ac801bb8b0f"
            ],
            "layout": "IPY_MODEL_6df1cbd26bf4468fbdd80984e2abff50"
          }
        },
        "f8527ed7e6594c8fa7e6da80133d81a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d56e796a514f6a93b82352d6f0da59",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d5808f25cbbe4020b6c995ea4063def9",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "e2b24e273d554fa0985061860d3a665a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704a89b43023428d8aa39ec5daab4e94",
            "max": 763,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1669505279fb4ae78231abaedcbb7ec2",
            "value": 763
          }
        },
        "0626152a942a4c8998b84ac801bb8b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8168b0d24849de9c972fd5a3dfda17",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0454b78a036b46ebb07cf2f952b32930",
            "value": "‚Äá763/763‚Äá[00:09&lt;00:00,‚Äá824.64it/s,‚ÄáMaterializing‚Äáparam=model.vision_model.post_layernorm.weight]"
          }
        },
        "6df1cbd26bf4468fbdd80984e2abff50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d56e796a514f6a93b82352d6f0da59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5808f25cbbe4020b6c995ea4063def9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "704a89b43023428d8aa39ec5daab4e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1669505279fb4ae78231abaedcbb7ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf8168b0d24849de9c972fd5a3dfda17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0454b78a036b46ebb07cf2f952b32930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Test idefics2 on RBNR dataset"
      ],
      "metadata": {
        "id": "Xx43zCn4lPVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a ready-to-use notebook for the use of idefics2 on the RBNR dataset. You just need to run the cells, the download of the dataset and the model is also managed, and see how it goes. You can also edit some parameter and the path for dataset if you want to use another one to test idefics2 on it."
      ],
      "metadata": {
        "id": "GgY1uEYOlR5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 1 - parameters and dependencies"
      ],
      "metadata": {
        "id": "zh74fQh-pDsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*First* of all we need to import and install the dependencies:\n",
        "\n",
        "**File and Dataset**\n",
        "\n",
        "* **os** ‚Äì filesystem operations\n",
        "* **gdown** ‚Äì download dataset from Google Drive\n",
        "* **zipfile / tarfile** ‚Äì extract compressed files\n",
        "* **pathlib** ‚Äì manage file paths\n",
        "\n",
        "**Model and Inference**\n",
        "\n",
        "* **torch / torchvision** ‚Äì deep learning framework and image transformations\n",
        "* **transformers** ‚Äì load model, processor, tokenizer\n",
        "* **bitsandbytes** ‚Äì 4-bit quantization support\n",
        "* **peft** ‚Äì parameter-efficient fine-tuning\n",
        "* **PIL (Pillow)** ‚Äì image loading and processing\n",
        "* **io.BytesIO** ‚Äì handle image streams\n",
        "* **gc** ‚Äì garbage collection for memory management\n",
        "* **time** ‚Äì manage delays for safe memory clearance\n",
        "\n",
        "**Image Preprocessing**\n",
        "\n",
        "* **torchvision.transforms** ‚Äì image transformations\n",
        "* **torchvision.transforms.functional** ‚Äì interpolation methods\n",
        "* **transformers.image_utils.load_image** ‚Äì load images from URLs or files\n",
        "\n",
        "**Text and Regex**\n",
        "\n",
        "* **re** ‚Äì extract digits or patterns from model outputs\n",
        "* **json** ‚Äì read/write configuration files (if needed)\n",
        "\n",
        "**Evaluation**\n",
        "\n",
        "* **scikit-learn (metrics)** ‚Äì compute precision, recall, F1\n",
        "* **matplotlib.pyplot** ‚Äì plot results, confusion matrices\n"
      ],
      "metadata": {
        "id": "9I7VObDFo67_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes accelerate transformers safetensors\n",
        "!pip install -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -U git+https://github.com/huggingface/peft.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqK4hLV631Ik",
        "outputId": "439c0a24-14da-446b-a439-b624277c3031",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.49.0\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-f40551l7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-f40551l7\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 0a8465420eecbac1c6d7dd9f45c08dd96b8c5027\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (3.20.0)\n",
            "Collecting huggingface-hub<2.0,>=1.2.1 (from transformers==5.0.0.dev0)\n",
            "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.22.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.20.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2025.11.12)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (0.16.0)\n",
            "Downloading huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m521.0/521.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=10992422 sha256=043b3baeecd9aa854a51e4d0cf9a82dcbedcced8732da7849bb9498f6b05d9f2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zcrn9t51/wheels/54/cb/3f/83103de5575c534436d6a4686686dead458238dfaf1147e98d\n",
            "Successfully built transformers\n",
            "Installing collected packages: huggingface-hub, transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.36.0\n",
            "    Uninstalling huggingface-hub-0.36.0:\n",
            "      Successfully uninstalled huggingface-hub-0.36.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.3\n",
            "    Uninstalling transformers-4.57.3:\n",
            "      Successfully uninstalled transformers-4.57.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-1.2.3 transformers-5.0.0.dev0\n",
            "Collecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-grwn8s95\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-grwn8s95\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 261366de2e40cde64b702d6b9c527081ad850549\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (5.0.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (1.12.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.18.1.dev0) (1.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft==0.18.1.dev0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.18.1.dev0) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.1.dev0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.1.dev0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.18.1.dev0) (0.22.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.18.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.18.1.dev0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->peft==0.18.1.dev0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->peft==0.18.1.dev0) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub>=0.25.0->peft==0.18.1.dev0) (8.3.1)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.18.1.dev0-py3-none-any.whl size=569869 sha256=397b464ca62ae9bf357de61d1f93c14f882799f6ba43b397f28627d4d61e14ab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-41jrj3hl/wheels/5d/16/61/117d50be36b7cb532817817523554825ff840d223c0f65c2c4\n",
            "Successfully built peft\n",
            "Installing collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.18.0\n",
            "    Uninstalling peft-0.18.0:\n",
            "      Successfully uninstalled peft-0.18.0\n",
            "Successfully installed peft-0.18.1.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Nc4bLNtjzPlf"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import tarfile\n",
        "import pathlib\n",
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "import re\n",
        "\n",
        "import gc\n",
        "import time\n",
        "\n",
        "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
        "from transformers import AutoModelForVision2Seq, BitsAndBytesConfig\n",
        "\n",
        "from transformers.image_utils import load_image\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets lets define some **variables** that are useful for the notebook. Path of the **drive dataset**, **prompt**, **num_token** can be modified here."
      ],
      "metadata": {
        "id": "Fj5jU2w4pR7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH AND DATASET\n",
        "\n",
        "dataset_link = 'https://drive.google.com/uc?id=12W-bY7SuctltDqHhl-OkI1DzwrcGnvJM'\n",
        "dataset_extract_path = \"./\"            # folder where to extract the files\n",
        "dataset_images_subfolder = 'cropped_RBNR_bib_dataset/images'  # subfolder with images\n",
        "labels_path = 'cropped_RBNR_bib_dataset/labels.txt'   # path to the labels file\n",
        "\n",
        "# MODEL PARAMETERS\n",
        "\n",
        "model_name = \"HuggingFaceM4/idefics2-8b\"  # pretrained model\n",
        "DEVICE = \"cuda:0\"                          # device to run the model (GPU)\n",
        "max_new_tokens = 500                        # maximum number of generated tokens\n",
        "\n",
        "\n",
        "# INFERENCE PARAMETERS\n",
        "prompt_text = \"What number do you see?\"\n",
        "\n",
        "\n",
        "# OUTPUT PARAMETERS\n",
        "\n",
        "predictions_output_path = './predictions.txt'  # file to save the predictions\n"
      ],
      "metadata": {
        "id": "szxX1qgCmSoe"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 2 ( optional ) - download dataset"
      ],
      "metadata": {
        "id": "WFHqC7wFpkbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am kinldy hosting the dataset for you on my google drive , I don't know until when... To download it from there I use **gdown** to get the zip, then the **zipfile** library to extract it"
      ],
      "metadata": {
        "id": "X6qn5Zvzpnh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(dataset_extract_path, exist_ok=True)\n",
        "\n",
        "# Function to download a file if it is not already present\n",
        "def download_if_needed(filename, url):\n",
        "    file_path = os.path.join(dataset_extract_path, filename)\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"üì• Downloading {filename} from Google Drive...\")\n",
        "        gdown.download(url, file_path, quiet=False)\n",
        "    return file_path\n",
        "\n",
        "# Download the files\n",
        "x_dev_path_compressed = download_if_needed(\"./dataset.zip\", dataset_link)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK2SZ7aL1aiP",
        "outputId": "d2ed4e57-2159-4149-fb3c-c2ffb9f0991e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Downloading ./dataset.zip from Google Drive...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12W-bY7SuctltDqHhl-OkI1DzwrcGnvJM\n",
            "To: /content/dataset.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 797k/797k [00:00<00:00, 146MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the downloaded file\n",
        "compressed_file = x_dev_path_compressed\n",
        "\n",
        "os.makedirs(dataset_extract_path, exist_ok=True)\n",
        "\n",
        "# Extract everything\n",
        "# Check if the file is a zip file before attempting to open it as tar.gz\n",
        "with zipfile.ZipFile(compressed_file, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(path=dataset_extract_path)\n",
        "\n",
        "print(f\"‚úÖ Files extracted to: {dataset_extract_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UuMvdiS4yyf",
        "outputId": "c16b8582-1a3a-46cc-afa0-0ea507f7d64a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Files extracted to: ./\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 3 - Load model and inference"
      ],
      "metadata": {
        "id": "yLCQ98CFp-gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "quant_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "model = AutoModelForVision2Seq.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "ec51ffd8ba934854946d5c05f062f3f4",
            "f8527ed7e6594c8fa7e6da80133d81a8",
            "e2b24e273d554fa0985061860d3a665a",
            "0626152a942a4c8998b84ac801bb8b0f",
            "6df1cbd26bf4468fbdd80984e2abff50",
            "c1d56e796a514f6a93b82352d6f0da59",
            "d5808f25cbbe4020b6c995ea4063def9",
            "704a89b43023428d8aa39ec5daab4e94",
            "1669505279fb4ae78231abaedcbb7ec2",
            "cf8168b0d24849de9c972fd5a3dfda17",
            "0454b78a036b46ebb07cf2f952b32930"
          ]
        },
        "id": "Wwn5M4Zez4my",
        "outputId": "d9b76c34-d1f3-4f8b-9072-75ae47d05fc9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/auto/modeling_auto.py:2287: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/763 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec51ffd8ba934854946d5c05f062f3f4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_memory():\n",
        "    # Delete variables if they exist in the current global scope\n",
        "    if 'inputs' in globals(): del globals()['inputs']\n",
        "    if 'model' in globals(): del globals()['model']\n",
        "    if 'processor' in globals(): del globals()['processor']\n",
        "    if 'trainer' in globals(): del globals()['trainer']\n",
        "    if 'peft_model' in globals(): del globals()['peft_model']\n",
        "    if 'bnb_config' in globals(): del globals()['bnb_config']\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Garbage collection and clearing CUDA memory\n",
        "    gc.collect()\n",
        "    time.sleep(2)\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "    time.sleep(2)\n",
        "    gc.collect()\n",
        "    time.sleep(2)\n",
        "\n",
        "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FUMrzovu0Ndp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHp9NDLW2gqC",
        "outputId": "90496017-7848-4df6-f72d-c4d74793e3d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU allocated memory: 0.00 GB\n",
            "GPU reserved memory: 0.00 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "images_path = pathlib.Path(dataset_images_subfolder)\n",
        "predictions = []\n",
        "\n",
        "\n",
        "for bib in sorted(os.listdir(images_path)):\n",
        "\n",
        "  img_path = os.path.join(images_path, bib)\n",
        "  img = load_image(str(img_path))\n",
        "\n",
        "  if img is None:\n",
        "    predictions.append('nan')\n",
        "    continue\n",
        "\n",
        "  responses = []\n",
        "\n",
        "  messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": prompt_text},\n",
        "        ]\n",
        "    },\n",
        "  ]\n",
        "\n",
        "  # First, apply the chat template to get the formatted prompt string\n",
        "  prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "  # Then, pass the prompt string to the processor along with images\n",
        "  inputs = processor(text=prompt, images=[img], return_tensors=\"pt\")\n",
        "  inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "\n",
        "  generated_ids = model.generate(**inputs, max_new_tokens=100)\n",
        "  response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "  if response and len(response) > 0:\n",
        "      response = re.findall(r'\\b\\d+\\b', response)\n",
        "  else:\n",
        "      response = []\n",
        "\n",
        "  if not response:\n",
        "    predictions.append('nan')\n",
        "  else:\n",
        "    predictions.append(response[0])\n",
        "\n",
        "  print(predictions[-1])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "61yLUKi_53A0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd1ba13-e14e-4304-83c8-8204d684c2ba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3638\n",
            "3637\n",
            "3719\n",
            "3719\n",
            "3531\n",
            "3531\n",
            "979\n",
            "979\n",
            "184\n",
            "2583\n",
            "2605\n",
            "2605\n",
            "2605\n",
            "2605\n",
            "2605\n",
            "463\n",
            "1463\n",
            "2251\n",
            "2078\n",
            "2078\n",
            "168\n",
            "822\n",
            "898\n",
            "3648\n",
            "869\n",
            "599\n",
            "311\n",
            "31\n",
            "1130\n",
            "858\n",
            "858\n",
            "3369\n",
            "3369\n",
            "2874\n",
            "2874\n",
            "25\n",
            "723\n",
            "163\n",
            "976\n",
            "287\n",
            "2103\n",
            "400\n",
            "755\n",
            "2747\n",
            "2925\n",
            "2649\n",
            "663\n",
            "663\n",
            "80\n",
            "1777\n",
            "177\n",
            "2845\n",
            "331\n",
            "3645\n",
            "2692\n",
            "2692\n",
            "3523\n",
            "3527\n",
            "3548\n",
            "3614\n",
            "3588\n",
            "814\n",
            "3035\n",
            "1404\n",
            "1679\n",
            "941\n",
            "941\n",
            "435\n",
            "435\n",
            "3225\n",
            "3708\n",
            "2244\n",
            "3628\n",
            "3241\n",
            "560\n",
            "1478\n",
            "3633\n",
            "341\n",
            "1676\n",
            "3621\n",
            "847\n",
            "58\n",
            "331\n",
            "3638\n",
            "3638\n",
            "1183\n",
            "168\n",
            "847\n",
            "3655\n",
            "168\n",
            "1676\n",
            "48\n",
            "690\n",
            "478\n",
            "1442\n",
            "1442\n",
            "1703\n",
            "2908\n",
            "3637\n",
            "3276\n",
            "61527\n",
            "61074\n",
            "71652\n",
            "20431\n",
            "10168\n",
            "10910\n",
            "1026\n",
            "11245\n",
            "11040\n",
            "1103\n",
            "10220\n",
            "10246\n",
            "2001\n",
            "22216\n",
            "21317\n",
            "30793\n",
            "31577\n",
            "30513\n",
            "35031\n",
            "30416\n",
            "30270\n",
            "61539\n",
            "1517\n",
            "70433\n",
            "80344\n",
            "15657\n",
            "5022\n",
            "60452\n",
            "31474\n",
            "20927\n",
            "60351\n",
            "70322\n",
            "90135\n",
            "82007\n",
            "61423\n",
            "60511\n",
            "80635\n",
            "453\n",
            "70511\n",
            "10679\n",
            "10165\n",
            "10933\n",
            "10190\n",
            "1140\n",
            "10\n",
            "709988\n",
            "11\n",
            "10175\n",
            "10191\n",
            "10168\n",
            "11142\n",
            "10144\n",
            "10227\n",
            "10159\n",
            "10171\n",
            "10216\n",
            "891\n",
            "1234\n",
            "10145\n",
            "19078\n",
            "10145\n",
            "10780\n",
            "11050\n",
            "nan\n",
            "10265\n",
            "10\n",
            "10971\n",
            "81991\n",
            "81991\n",
            "11110\n",
            "11187\n",
            "10691\n",
            "10330\n",
            "11453\n",
            "11453\n",
            "11454\n",
            "100\n",
            "4345\n",
            "4454\n",
            "3778\n",
            "4407\n",
            "3855\n",
            "3236\n",
            "3482\n",
            "775\n",
            "775\n",
            "3594\n",
            "3855\n",
            "3482\n",
            "1518\n",
            "37641\n",
            "248\n",
            "2254\n",
            "3555\n",
            "1251\n",
            "4380\n",
            "3482\n",
            "3855\n",
            "3594\n",
            "2973\n",
            "1518\n",
            "3631\n",
            "1164\n",
            "2830\n",
            "1414\n",
            "729\n",
            "1495\n",
            "2121\n",
            "4242\n",
            "3122\n",
            "3250\n",
            "1718\n",
            "1419\n",
            "1962\n",
            "1841\n",
            "2091\n",
            "3608\n",
            "3352\n",
            "2446\n",
            "3919\n",
            "949\n",
            "3959\n",
            "4178\n",
            "2404\n",
            "3466\n",
            "3375\n",
            "352\n",
            "3054\n",
            "3054\n",
            "2881\n",
            "1581\n",
            "139\n",
            "1975\n",
            "1454\n",
            "3717\n",
            "2564\n",
            "3558\n",
            "1466\n",
            "2464\n",
            "4241\n",
            "3855\n",
            "4208\n",
            "2802\n",
            "2551\n",
            "4025\n",
            "3470\n",
            "1628\n",
            "421\n",
            "2327\n",
            "4570\n",
            "4189\n",
            "4345\n",
            "4649\n",
            "3271\n",
            "331\n",
            "3750\n",
            "354\n",
            "2074\n",
            "3286\n",
            "3457\n",
            "1859\n",
            "3671\n",
            "2167\n",
            "3355\n",
            "1777\n",
            "3298\n",
            "2648\n",
            "4606\n",
            "3591\n",
            "858\n",
            "337\n",
            "858\n",
            "4173\n",
            "4333\n",
            "4346\n",
            "1055\n",
            "3555\n",
            "198\n",
            "753\n",
            "3783\n",
            "4622\n",
            "723\n",
            "231\n",
            "4624\n",
            "2244\n",
            "nan\n",
            "973\n",
            "4183\n",
            "1880\n",
            "2813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "with open('predictions.txt', 'w') as f:\n",
        "    for line in predictions:\n",
        "        f.write(\"\".join(line) + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihsE0dSi61qy",
        "outputId": "6a1f692e-5857-4c42-a5fa-bc14dc3e424f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3638', '3637', '3719', '3719', '3531', '3531', '979', '979', '184', '2583', '2605', '2605', '2605', '2605', '2605', '463', '1463', '2251', '2078', '2078', '168', '822', '898', '3648', '869', '599', '311', '31', '1130', '858', '858', '3369', '3369', '2874', '2874', '25', '723', '163', '976', '287', '2103', '400', '755', '2747', '2925', '2649', '663', '663', '80', '1777', '177', '2845', '331', '3645', '2692', '2692', '3523', '3527', '3548', '3614', '3588', '814', '3035', '1404', '1679', '941', '941', '435', '435', '3225', '3708', '2244', '3628', '3241', '560', '1478', '3633', '341', '1676', '3621', '847', '58', '331', '3638', '3638', '1183', '168', '847', '3655', '168', '1676', '48', '690', '478', '1442', '1442', '1703', '2908', '3637', '3276', '61527', '61074', '71652', '20431', '10168', '10910', '1026', '11245', '11040', '1103', '10220', '10246', '2001', '22216', '21317', '30793', '31577', '30513', '35031', '30416', '30270', '61539', '1517', '70433', '80344', '15657', '5022', '60452', '31474', '20927', '60351', '70322', '90135', '82007', '61423', '60511', '80635', '453', '70511', '10679', '10165', '10933', '10190', '1140', '10', '709988', '11', '10175', '10191', '10168', '11142', '10144', '10227', '10159', '10171', '10216', '891', '1234', '10145', '19078', '10145', '10780', '11050', 'nan', '10265', '10', '10971', '81991', '81991', '11110', '11187', '10691', '10330', '11453', '11453', '11454', '100', '4345', '4454', '3778', '4407', '3855', '3236', '3482', '775', '775', '3594', '3855', '3482', '1518', '37641', '248', '2254', '3555', '1251', '4380', '3482', '3855', '3594', '2973', '1518', '3631', '1164', '2830', '1414', '729', '1495', '2121', '4242', '3122', '3250', '1718', '1419', '1962', '1841', '2091', '3608', '3352', '2446', '3919', '949', '3959', '4178', '2404', '3466', '3375', '352', '3054', '3054', '2881', '1581', '139', '1975', '1454', '3717', '2564', '3558', '1466', '2464', '4241', '3855', '4208', '2802', '2551', '4025', '3470', '1628', '421', '2327', '4570', '4189', '4345', '4649', '3271', '331', '3750', '354', '2074', '3286', '3457', '1859', '3671', '2167', '3355', '1777', '3298', '2648', '4606', '3591', '858', '337', '858', '4173', '4333', '4346', '1055', '3555', '198', '753', '3783', '4622', '723', '231', '4624', '2244', 'nan', '973', '4183', '1880', '2813']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 4 - evaluation"
      ],
      "metadata": {
        "id": "sOjBiIIly_i_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our prediction we evaluate the result in 2 way:\n",
        "\n",
        "\n",
        "*   **complete number**: basically we count as True Positive only if the number predicted and the label perfectly match\n",
        "*   **by digit**: instead of evaluating the full number we evaluate the single digits of each number\n",
        "\n"
      ],
      "metadata": {
        "id": "WcpzyUp7zAId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(labels_path: str, predictions_path: str) -> tuple[float, float, float]:\n",
        "\n",
        "    labels = []\n",
        "    with open(labels_path, 'r') as f:\n",
        "        for line in f:\n",
        "            labels.append(line.strip())\n",
        "\n",
        "    predictions = []\n",
        "    with open(predictions_path, 'r') as f:\n",
        "        for line in f:\n",
        "            predictions.append(line.strip())\n",
        "\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "\n",
        "        if prediction == 'nan':\n",
        "            FN +=1\n",
        "            continue\n",
        "\n",
        "        if prediction == label:\n",
        "            TP+=1\n",
        "            continue\n",
        "\n",
        "        FP+=1\n",
        "\n",
        "    P = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    R = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    F1 = 2 * (R * P) / (R + P) if (R + P) > 0 else 0.0\n",
        "    return P, R, F1\n"
      ],
      "metadata": {
        "id": "eKjB5vgrDWar"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_digit(labels_path: str, predictions_path: str) -> tuple[float, float, float]:\n",
        "\n",
        "    labels = []\n",
        "    with open(labels_path, 'r') as f:\n",
        "        for line in f:\n",
        "            labels.append(line.strip())\n",
        "\n",
        "    predictions = []\n",
        "    with open(predictions_path, 'r') as f:\n",
        "        for line in f:\n",
        "            predictions.append(line.strip())\n",
        "\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "\n",
        "\n",
        "        if prediction == 'nan':\n",
        "            FN +=1\n",
        "            continue\n",
        "\n",
        "        max_len = max(len(label), len(prediction))\n",
        "\n",
        "        for i in range(max_len):\n",
        "            true_digit = label[i] if i < len(label) else None\n",
        "            pred_digit = prediction[i] if i < len(prediction) else None\n",
        "\n",
        "            if true_digit is not None and pred_digit is not None: #if i can compare them\n",
        "                if true_digit == pred_digit:\n",
        "                    TP += 1 # right predition -> TP\n",
        "                else:\n",
        "                    FP += 1  # wrong prediction -> FP\n",
        "            elif true_digit is not None and pred_digit is None:# if i dont predict a digit -> FN\n",
        "                FN += 1\n",
        "            elif pred_digit is not None and true_digit is None:\n",
        "                FP += 1  # if i predict some digit that do not exist -> FP\n",
        "\n",
        "    P = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    R = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    F1 = 2 * (R * P) / (R + P) if (R + P) > 0 else 0.0\n",
        "    return P, R, F1\n",
        "    print(f\"PRECISION: {precision_score(y_true=y_true, y_pred=y_pred)}\")\n",
        "    print(f\"RECALL: {recall_score(y_true=y_true, y_pred=y_pred)}\")\n",
        "    print(f\"F1: {f1_score(y_true=y_true, y_pred=y_pred)}\")\n"
      ],
      "metadata": {
        "id": "n4ephu4zFeda"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_digit, R_digit, F1_digit = evaluate_digit(labels_path, predictions_output_path)\n",
        "P_full, R_full, F1_full = evaluate(labels_path, predictions_output_path)\n",
        "\n",
        "print(\"===== üìä RISULTATI SAIL-VL =====\")\n",
        "print(\"\\nFull number evaluation:\")\n",
        "print(f\"Precisione: {P_full*100:.2f}%\")\n",
        "print(f\"Recall:     {R_full*100:.2f}%\")\n",
        "print(f\"F1-score:   {F1_full*100:.2f}%\")\n",
        "\n",
        "print(\"\\nDigit evaluation:\")\n",
        "print(f\"Precisione: {P_digit*100:.2f}%\")\n",
        "print(f\"Recall:     {R_digit*100:.2f}%\")\n",
        "print(f\"F1-score:   {F1_digit*100:.2f}%\")\n",
        "\n",
        "print(\"\\n=================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJkeNpK3FnIi",
        "outputId": "9c13b122-d0f5-451f-ae5a-63b9ecf869fc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== üìä RISULTATI SAIL-VL =====\n",
            "\n",
            "Full number evaluation:\n",
            "Precisione: 88.54%\n",
            "Recall:     99.22%\n",
            "F1-score:   93.58%\n",
            "\n",
            "Digit evaluation:\n",
            "Precisione: 95.02%\n",
            "Recall:     97.05%\n",
            "F1-score:   96.02%\n",
            "\n",
            "=================================\n"
          ]
        }
      ]
    }
  ]
}