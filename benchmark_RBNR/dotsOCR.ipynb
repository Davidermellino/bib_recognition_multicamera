{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTHMKfNtFXJ6"
   },
   "source": [
    "#Test dotsOCR for RBNR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRzUCuW2FxsS"
   },
   "source": [
    "This is a ready-to-use notebook for the use of dotsOCR on the RBNR dataset. You just need to run the cells, the download of the dataset and the model is also managed, and see how it goes. You can also edit some parameter and the path for dataset if you want to use another one to test dotsOCR on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KvhOwtOGY-g"
   },
   "source": [
    "## SECTION 1 - parameters and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guy8bKWbgWM-"
   },
   "source": [
    "*First* of all we need to install the dependencies:\n",
    "\n",
    "\n",
    "**File and Dataset**\n",
    "\n",
    "* **os** â€“ filesystem operations\n",
    "* **gdown** â€“ download dataset from Google Drive\n",
    "* **zipfile / tarfile** â€“ extract compressed files\n",
    "* **pathlib** â€“ manage file paths\n",
    "\n",
    "**Model and Inference**\n",
    "\n",
    "* **dots_ocr** â€“ our model, we will install it via github\n",
    "* **dots_ocr.utils** â€“ helper functions for prompts\n",
    "* **torch** â€“ deep learning framework\n",
    "* **transformers** â€“ load model, processor, tokenizer\n",
    "* **qwen_vl_utils** â€“ prepare image + text input\n",
    "\n",
    "**Text and Regex**\n",
    "\n",
    "* **re** â€“ extract digits from output\n",
    "* **json** â€“ read/write config files\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "* **scikit-learn (metrics)** â€“ compute precision, recall, F1\n",
    "* **matplotlib** â€“ plot results, confusion matrices\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjcvs5hOi2Zg"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/rednote-hilab/dots.ocr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F28w44NtoKoy"
   },
   "outputs": [],
   "source": [
    "!python3 dots.ocr/tools/download_model.py #download dots_ocs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMxBdXbuj5vr"
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu128\n",
    "%cd /content/dots.ocr\n",
    "!pip install -e .\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrNnD2GiGjct"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, AutoTokenizer\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "%cd /content/dots.ocr\n",
    "from dots_ocr.utils import dict_promptmode_to_prompt\n",
    "%cd ../\n",
    "\n",
    "import json\n",
    "import re\n",
    "import pathlib\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wcK_uhSHO9F"
   },
   "source": [
    "Now lets lets define some **variables** that are useful for the notebook. Path of the **drive dataset**, **prompt**, **num_token** can be modified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jti3lcNrHOSF"
   },
   "outputs": [],
   "source": [
    "\n",
    "#DATASET PARAMETERS\n",
    "dataset_link = 'https://drive.google.com/uc?id=12W-bY7SuctltDqHhl-OkI1DzwrcGnvJM'\n",
    "dataset_extract_path = './'\n",
    "dataset_images_subfolder = '/content/cropped_RBNR_bib_dataset/images'\n",
    "labels_path = '/content/cropped_RBNR_bib_dataset/labels.txt'\n",
    "\n",
    "#MODEL PARAMETER\n",
    "model_path = \"dots.ocr/weights/DotsOCR\" #should not be modified ( is a path from the dotsOCR library )\n",
    "attn_impl = \"flash_attention_2\"\n",
    "device = 'cuda'\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "#INFERENCE PARAMETERS\n",
    "prompt_text = \"\"\"What number is visible on the racing bib in this image?\"\"\" #prompt that dotsOCR will recive to make inference\n",
    "digit_regex = r'\\b\\d{2,6}\\b'\n",
    "max_token = 16 #max number of the token that will be generated\n",
    "temperature = 1\n",
    "repetition_penalty = 1\n",
    "max_digit_length = 6\n",
    "problematic_img = ['set3_06_0.JPG'] #some img make the script crash\n",
    "\n",
    "#EVALUATION PARAMETERS\n",
    "predictions_output_path = '../predictions.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HM5qt4v-i715"
   },
   "source": [
    "## SECTION 2 ( optional ) - download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dELO6CMajPZC"
   },
   "source": [
    "I am kinldy hosting the dataset for you on my google drive , I don't know until when... To download it from there I use **gdown** to get the zip, then the **zipfile** library to extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lbo7Chhn6Ke"
   },
   "outputs": [],
   "source": [
    "os.makedirs(dataset_extract_path, exist_ok=True)\n",
    "\n",
    "# Function to download a file if it is not already present\n",
    "def download_if_needed(filename, url):\n",
    "    file_path = os.path.join(dataset_extract_path, filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"ðŸ“¥ Downloading {filename} from Google Drive...\")\n",
    "        gdown.download(url, file_path, quiet=False)\n",
    "    return file_path\n",
    "\n",
    "# Download the files\n",
    "x_dev_path_compressed = download_if_needed(\"./dataset.zip\", dataset_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UohQ1Ew_n87g"
   },
   "outputs": [],
   "source": [
    "# Path to the downloaded file\n",
    "compressed_file = x_dev_path_compressed\n",
    "\n",
    "os.makedirs(dataset_extract_path, exist_ok=True)\n",
    "\n",
    "# Extract everything\n",
    "# Check if the file is a zip file before attempting to open it as tar.gz\n",
    "with zipfile.ZipFile(compressed_file, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(path=dataset_extract_path)\n",
    "\n",
    "print(f\"âœ… Files extracted to: {dataset_extract_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XvTftS2j8nb"
   },
   "source": [
    "# SECTION 3 - Load model and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MR6wmqGLAV0d"
   },
   "outputs": [],
   "source": [
    "model_path = model_path\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    attn_implementation=attn_impl,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK6XVcWp-sqp"
   },
   "outputs": [],
   "source": [
    "def dots_ocr_inference(image_path):\n",
    "\n",
    "  prompt = prompt_text\n",
    "  messages = [\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": [\n",
    "                  {\n",
    "                      \"type\": \"image\",\n",
    "                      \"image\": image_path\n",
    "                  },\n",
    "                  {\"type\": \"text\", \"text\": prompt}\n",
    "              ]\n",
    "          }\n",
    "      ]\n",
    "\n",
    "  # Prepare the image + text imput\n",
    "  text = processor.apply_chat_template(\n",
    "      messages,\n",
    "      tokenize=False,\n",
    "      add_generation_prompt=True\n",
    "  )\n",
    "\n",
    "  image_inputs, video_inputs = process_vision_info(messages)\n",
    "  inputs = processor(\n",
    "      text=[text],\n",
    "      images=image_inputs,\n",
    "      videos=video_inputs,\n",
    "      padding=True,\n",
    "      return_tensors=\"pt\",\n",
    "  )\n",
    "\n",
    "  inputs = inputs.to(\"cuda\")\n",
    "\n",
    "  # Inference: Generation of the output\n",
    "  generated_ids = model.generate(**inputs,\n",
    "                                 max_new_tokens=max_token,\n",
    "                                 temperature = temperature,\n",
    "                                 repetition_penalty = repetition_penalty)\n",
    "\n",
    "  generated_ids_trimmed = [\n",
    "      out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "  ]\n",
    "\n",
    "  output_text = processor.batch_decode(\n",
    "      generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "  )\n",
    "\n",
    "  #check if the prediction satisfy the regex condition (2 to 6 digit in this notebook)\n",
    "  digits = re.findall(digit_regex, output_text[0])\n",
    "  pred = \"\".join(digits)\n",
    "\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSRpNilEVVui"
   },
   "outputs": [],
   "source": [
    "images_path = pathlib.Path(dataset_images_subfolder)\n",
    "predictions = []\n",
    "\n",
    "i = 0\n",
    "for bib in sorted(os.listdir(images_path)):\n",
    "    i += 1\n",
    "    if bib in problematic_img:\n",
    "      predictions.append('nan')\n",
    "      continue\n",
    "    print(f'computing {bib}')\n",
    "\n",
    "    img_path = os.path.join(images_path, bib)\n",
    "    result = dots_ocr_inference(img_path)\n",
    "\n",
    "    #if the number has more than 6 digit it sign it as nan\n",
    "    if len(result) > max_digit_length:\n",
    "      result = 'nan'\n",
    "\n",
    "    print(f'[{i}/{len(os.listdir(images_path))}] SUCCESS: {result}')\n",
    "    predictions.append(result)\n",
    "\n",
    "#save predictions\n",
    "with open(predictions_output_path, 'w') as f:\n",
    "    for line in predictions:\n",
    "        f.write(\"\".join(line) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYtwS8lBl0RB"
   },
   "source": [
    "# SECTION 4 - evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtY-vwKNmFZY"
   },
   "source": [
    "Now that we have our prediction we evaluate the result in 2 way:\n",
    "\n",
    "\n",
    "*   **complete number**: basically we count as True Positive only if the number predicted and the label perfectly match\n",
    "*   **by digit**: instead of evaluating the full number we evaluate the single digits of each number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ClwaSNvVX8p"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(labels_path: str, predictions_path: str) -> tuple[float, float, float]:\n",
    "\n",
    "    labels = []\n",
    "    with open(labels_path, 'r') as f:\n",
    "        for line in f:\n",
    "            labels.append(line.strip())\n",
    "\n",
    "    predictions = []\n",
    "    with open(predictions_path, 'r') as f:\n",
    "        for line in f:\n",
    "            predictions.append(line.strip())\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if prediction == 'nan':\n",
    "            FN +=1\n",
    "            continue\n",
    "\n",
    "        if prediction == label:\n",
    "            TP+=1\n",
    "            continue\n",
    "\n",
    "        FP+=1\n",
    "\n",
    "    P = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    R = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    F1 = 2 * (R * P) / (R + P) if (R + P) > 0 else 0.0\n",
    "    return P, R, F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXhCX5CEoytU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_digit(labels_path: str, predictions_path: str) -> tuple[float, float, float]:\n",
    "\n",
    "    labels = []\n",
    "    with open(labels_path, 'r') as f:\n",
    "        for line in f:\n",
    "            labels.append(line.strip())\n",
    "\n",
    "    predictions = []\n",
    "    with open(predictions_path, 'r') as f:\n",
    "        for line in f:\n",
    "            predictions.append(line.strip())\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if prediction == 'nan':\n",
    "            FN +=1\n",
    "            continue\n",
    "\n",
    "        max_len = max(len(label), len(prediction))\n",
    "\n",
    "        for i in range(max_len):\n",
    "            true_digit = label[i] if i < len(label) else None\n",
    "            pred_digit = prediction[i] if i < len(prediction) else None\n",
    "\n",
    "            if true_digit is not None and pred_digit is not None: #if i can compare them\n",
    "                if true_digit == pred_digit:\n",
    "                    TP += 1 # right predition -> TP\n",
    "                else:\n",
    "                    FP += 1  # wrong prediction -> FP\n",
    "            elif true_digit is not None and pred_digit is None:# if i dont predict a digit -> FN\n",
    "                FN += 1\n",
    "            elif pred_digit is not None and true_digit is None:\n",
    "                FP += 1  # if i predict some digit that do not exist -> FP\n",
    "\n",
    "    P = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    R = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    F1 = 2 * (R * P) / (R + P) if (R + P) > 0 else 0.0\n",
    "    return P, R, F1\n",
    "    print(f\"PRECISION: {precision_score(y_true=y_true, y_pred=y_pred)}\")\n",
    "    print(f\"RECALL: {recall_score(y_true=y_true, y_pred=y_pred)}\")\n",
    "    print(f\"F1: {f1_score(y_true=y_true, y_pred=y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1765884513724,
     "user": {
      "displayName": "Davide Ermellino",
      "userId": "16391069294145171419"
     },
     "user_tz": 0
    },
    "id": "SY-gW98PVcvH",
    "outputId": "f3184706-3884-4ead-ea38-e70f7b113f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ðŸ“Š RISULTATI DOTS OCR =====\n",
      "\n",
      "Full number evaluation:\n",
      "Precisione: 84.19%\n",
      "Recall:     92.71%\n",
      "F1-score:   88.25%\n",
      "\n",
      "Digit evaluation:\n",
      "Precisione: 94.58%\n",
      "Recall:     90.80%\n",
      "F1-score:   92.65%\n",
      "\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "P_digit, R_digit, F1_digit = evaluate_digit(labels_path, predictions_output_path)\n",
    "P_full, R_full, F1_full = evaluate(labels_path, predictions_output_path)\n",
    "\n",
    "print(\"===== ðŸ“Š RISULTATI DOTS OCR =====\")\n",
    "print(\"\\nFull number evaluation:\")\n",
    "print(f\"Precisione: {P_full*100:.2f}%\")\n",
    "print(f\"Recall:     {R_full*100:.2f}%\")\n",
    "print(f\"F1-score:   {F1_full*100:.2f}%\")\n",
    "\n",
    "print(\"\\nDigit evaluation:\")\n",
    "print(f\"Precisione: {P_digit*100:.2f}%\")\n",
    "print(f\"Recall:     {R_digit*100:.2f}%\")\n",
    "print(f\"F1-score:   {F1_digit*100:.2f}%\")\n",
    "\n",
    "print(\"\\n=================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSYFRQHv60yq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": [
    {
     "file_id": "1fjudJ-DBQ6lifkyKgKjpKylRD6E8Cdce",
     "timestamp": 1757088475631
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
